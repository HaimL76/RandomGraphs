\documentclass{article}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage{graphicx} % Required for inserting images

\title{RandomGraphs}
\author{haiml76 }
\date{August 2025}

\begin{document}

\maketitle

\section{}
\subsection{}
Let $G_0$ be a specific graph with $n$ vertices and $m_0$ edges, then $\mathbb{P}[G\sim{G(n,p)}=G_0]=p^{m_0}(1-p)^{\binom{n}{2}-m_0}\Rightarrow{\mathbb{P}[G\sim{G(n,p)}\in{A}]}=\mathbb{P}[\bigcup_{G_0\in{A}}G\sim{G(n,p)}=G_0]=\sum_{G_0\in{A}}p^{m_0}(1-p)^{\binom{n}{2}-m_0}$. But this is a polynomial in $p$, hence continous, and for every $0\leq{p\leq{q}}\leq{1}$. we have $\mathbb{P}[G\sim{G(n,p)}=G_0]=p^{m_0}(1-p)^{\binom{n}{2}-m_0}\leq{q^{m_0}(1-q)^{\binom{n}{2}-m_0}}=\mathbb{P}[G\sim{G(n,q)}=G_0]$, which applies also for the sum of probabilities over $\bigcup_{G_0\in{A}}G_0$. Thus, $f(p):=\mathbb{P}[G\sim{G(n,p)}\in{A}]$ is both continous and monotone increasing. We know that $\mathbb{P}[G\sim{G(n,0)}=\phi]=1\Rightarrow{\mathbb{P}[G\sim{G(n,0)}\in{A}]=0}$, and that $\mathbb{P}[G\sim{G(n,1)}\in{A}]=1$, hence $f(0)=0$ and $f(1)=1$, and by the intermediate value theorem, for each $0\leq{v}\leq{1}$, there must exist an argument $0\leq{p}\leq{1}$ s.t. $v=f(p)$. We choose $v=\frac{1}{2}$, hence there must exist some $0\leq{p^{\ast}}\leq{1}$ s.t. $v=f(p^{\ast})=\frac{1}{2}.$
\subsection{}
We check that $1-kp\leq{(1-p)^k}$, for all $k\in\mathbb{N}$, by induction.

For $k=1$ it is trivial, for $k+1$, we have $(1-p)^{k+1}=(1-p)^k(1-p)$, and by the assumption, $(1-p)^k(1-p)\geq{(1-kp)(1-p)}=1-kp-p+kp^2=1-(k+1)p+kp^2$, but $kp^2>0$, so $(1-p)^{k+1}=(1-p)^k(1-p)\geq{1-(k+1)p+kp^2}>1-(k+1)p$, which proves the assumption.

But it means that for each potential edge $e$, 

$\mathbb{P}[e\notin{G\sim{G(n,kp)}}]=1-kp\leq(1-p)^k=(\mathbb{P}[e\notin{G\sim{G(n,p)}}])^k=\mathbb{P}[e\notin{G\sim\bigcup_{i=1}^{k}G(n,p)}]\Rightarrow{\mathbb{P}[e\in{G\sim{G(n,kp)}}]\geq{\mathbb{P}[e\in{G\sim\bigcup_{i=1}^{k}G(n,p)]}}}$, 

but by a theorem coming from staged exposure, it means that if $A$ is an increasing monotone property, then $\mathbb{P}[G\sim{G(n,kp)}\in{A}]\geq{\mathbb{P}[G\sim\bigcup_{i=1}^{k}G(n,p)\in{A}]}\Rightarrow{\mathbb{P}[G\sim{G(n,kp)}\notin{A}]\leq{\mathbb{P}[G\sim\bigcup_{i=1}^{k}G(n,p)\notin{A}]}=(\mathbb{P}[G\sim{G(n,p)}\notin{A}]})^k$

\subsection{}
$\omega:=g(n)$, s.t. $\lim_{n\rightarrow\infty}g(n)=\infty$ and $\lim_{n\rightarrow\infty}\frac{g(n)}{n}=0$.

Let $n_k:=\min\{n\in\mathbb{N} : \lfloor{g(n_k)}\rfloor\geq{k}\}$, we are guaranteed to have such $n_k$ for every $k\geq{1}$, otherwise there exists some $k_0$ s.t. $\lfloor{g(n)}\rfloor\leq{k_0}$ for every $n\in\mathbb{N}$, in contradiction to $g(n)\rightarrow\infty$. 
Hence, for every $k\geq{1}$ we have $n_k\in\mathbb{N}$, s.t. $\mathbb{P}[G(n_k,g(n_k)p^{\ast})\notin{A}]\leq{\mathbb{P}[G(n_k,kp^{\ast})\notin{A}]}$, this is true because $g(n)\geq\lfloor{g(n)}\rfloor\geq{k}$ and $A$ is a monotone increasing property. But from 1.2 we know that $\mathbb{P}[G(n_k,kp^{\ast})\notin{A}]\leq{(\mathbb{P}[G(n_k,p^{\ast})\notin{A}])^k}$, but $\lim_{k\rightarrow\infty}(\mathbb{P}[G(n_k,p^{\ast})\notin{A}])^k=\lim_{k\rightarrow\infty}\frac{1}{2^k}=0\Rightarrow{\lim_{n\rightarrow\infty}\mathbb{P}[G(n,g(n){p^{\ast}})\in{A}]}=\lim\mathbb{P}[G(n,\omega{p^{\ast}})\in{A}]=1$.

For $\mathbb{P}[G(n,\frac{p^{\ast}}{g(n)})\in{A}]$, we observe that $0\leq{p^{\ast}}\leq{1}\Rightarrow{\lim_{n\rightarrow\infty}\frac{p^{\ast}}{g(n)}}\leq{\lim_{n\rightarrow\infty}\frac{1}{g(n)}}=0$, as $g(n)$ tends to infinity.
But then $\lim_{n\rightarrow\infty}\mathbb{P}[G(n,\frac{p^{\ast}}{g(n)})\in{A}]=\lim_{p\rightarrow{0}}\mathbb{P}[G(n,p)\in{A}]=\mathbb{P}[G(n,0)\in{A}]$, as $\mathbb{P}[G(n,p)\in{A}]$ is continuous, but from 1.1 we know that $\mathbb{P}[G(n,0)\in{A}]=0$.

\section{}
Intuitively, we observe that for any finite graph on $n\geq{3}$ vertices a triangle can appear starting from $m=3$ which is a constant, but the graph cannot be connected before at least $n-1$ edges appear, which depends on $n$, so when $n\rightarrow\infty$, the distance $(n-1)-3$ also tends to infinity. But we need to prove this formally.
We shall partially repeat some well-known facts. Let $G\sim{G(n,p)}$, the probability of having at least one triangle in $G$ has a threshold. Let $T$ be the number of triangles in $G$, then $\mathbb{E}[T]=\binom{n}{3}p^3\Rightarrow{\lim_{n\rightarrow\infty}}\mathbb{E}[T]=\lim_{n\rightarrow\infty}\binom{n}{3}p^3=\lim_{n\rightarrow\infty}\frac{n(n-1)(n-2)}{3!}p^3$. For every $0\leq{p(n)}\leq{1}$, we have 

$\lim_{n\rightarrow\infty}\frac{n(n-1)(n-2)}{6}p(n)^3=     \begin{cases}
       0, & p(n)<<\frac{1}{n}\\
       1, & p(n)>>\frac{1}{n}\\
     \end{cases}$

But by Markov's inequality, $\mathbb{P}[T\geq{1}]\leq\frac{\mathbb{E}[T]}{1}$, so in the case of $p(n)<<\frac{1}{n}$ we have that $\lim_{n\rightarrow\infty}\mathbb{P}[T\geq{1}]\leq{lim_{n\rightarrow\infty}\mathbb{E}[T]=0}$.
For $p>>\frac{1}{n}$, we use the second moment method, we have the inequality $\mathbb{P}[T\geq{1}]\geq{\frac{\mathbb{E}[T]^2}{\mathbb{E}[T^2]}}=\frac{[\binom{n}{3}p^3]^2}{\mathbb{E}[T^2]}$. But $T^2=\sum\mathbbm{1}_{\{i,j,k\}\in\mathcal{T}}\sum\mathbbm{1}_{\{f,g,h\}\in\mathcal{T}}$, where $\{i,j,k\}$ and $\{f,g,h\}$ are triplets of vertices and $\mathcal{T}$ is the set of all potential triangles in $G$. There are different ways to choose one triplet and then choose a second triplet, the one that yields the largest count of vertices is when $\{i,j,k\}\cap\{f,g,h\}=\phi$, we denote $T_0$ the potential number of triplets in the case of the intersection being $\phi$, which means no joint vertex, $T_1$ the case of one joint vertex, $T_2$ the case of two joint vertices, and $T_3$ the case of choosing the same triangle twice.

Thus $T_0=\binom{n}{3}\binom{n-3}{3}$. 

For $T_1$ we have $\binom{n}{3}$ choices of the first triplet, and $3$ options for choosing one of the vertices of the first triplet, and then $\binom{n-3}{2}$ choices for the other two vertices of the second triplet, so $T_1=3\binom{n}{3}\binom{n-3}{2}$, and $T_2=3\binom{n}{3}(n-3)$, and $T_3=\binom{n}{3}$. 

We observe that in the case of $T_0$ and the case of $T_1$ we have $6$ distinct edges for every two triangles, so their probability is $p^6$, but in the case of $T_2$ we have one joint edges, so only 5 distinct edges for every two triangles, and in the case of choosing the same triplet twice, we have the same three edges chosen twice, but the probability for that remains $p^3$. Thus the corresponding expectations of $T_1$, $T_2$ and $T_3$ are $O(n^5p^6)$, $O(n^4p^5)$ and $O(n^3p^3)$, respectively. Thus $\frac{\mathbb{E}[T]^2}{\mathbb{E}[T^2]}=\frac{\binom{n}{3}^2p^6}{\binom{n}{3}\binom{n-3}{3}p^6+o(n^6p^6)}=1-o(1)$, but $\mathbb{P}[T\geq{1}]\geq\frac{\mathbb{E}[T]^2}{\mathbb{E}[T^2]}=1-o(1)$. Notice that this is true only if $p>>\frac{1}{p}$, for which $\mathbb{E}[T]$ tends to infinity.

For connectedness, the threshold is $\frac{\log{n}}{n}$.
We know that for a random graph process, each step $0\leq{m}\leq\binom{n}{2}$ has the same distribution of $G(n,m)$, so we translate our thresholds from $G(n,p)$ to $G(n,m)$ by taking $m=\binom{n}{2}p+O(\sqrt{\binom{n}{2}p(1-p)})$. Thus, the $G(n,m)$ threshold for triangles becomes $m_t:=\binom{n}{2}\frac{1}{n}+O(\sqrt{\binom{n}{2}\frac{1}{n}(1-\frac{1}{n})})\approx\binom{n}{2}\frac{1}{n}$, and the threshold for connectedness becomes $m_c:=\binom{n}{2}\frac{\log{n}}{n}+O(\sqrt{\binom{n}{2}\frac{\log{n}}{n}(1-\frac{\log{n}}{n})})\approx\binom{n}{2}\frac{\log{n}}{n}$. We take the sequence $M_n:=\{\frac{m_c}{m_t}\}\approx\log{n}$, but $\lim_{n\rightarrow\infty}\log{n}=\infty$, hence $\lim_{n\rightarrow\infty}\mathbb{P}[m_c\geq{m_t}]=\lim_{n\rightarrow\infty}\mathbb{P}[\frac{m_c}{m_t}\geq{1}]=\infty$.

A more accurate solution is based on the book by Frieze and Karonski.
\begin{enumerate}
    \item Theorem 4.1 (from Erdos and Reyni)

    Let $m=\frac{1}{2}n(\log{n}+c_n)$. Then

    $\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,m)}\in\mathcal{C}]=\begin{cases}
        0, & c_n\rightarrow{-\infty} \\
        e^{-e^{-c}}, & c_n\rightarrow{c} \\
        1, & c_n\rightarrow\infty \\
    \end{cases}$

    where $\mathcal{C}$ is the property of being connected, and $c$ is some constant.

    \item Theorem 1.12
    
    If $\lim_{n\rightarrow\infty}\frac{m}{n}=\infty$ then $\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,m)}\in\mathcal{T}]=1$, where $\mathcal{T}$ is the property of having at least one triangle.

    \item Using the two theorems above. Let $c_0$ be some constant, and $m_0:=\frac{1}{2}n(\log{n}+c_0)$, then $\lim_{n\rightarrow\infty}\frac{m_0}{n}=\lim_{n\rightarrow\infty}\frac{n(\log{n}+c_0)}{2n}=\lim_{n\rightarrow\infty}\frac{\log{n}+c_0}{2}=\infty\Rightarrow{\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,m_0)}\in\mathcal{T}]}=1$, by theorem 4.1, but $\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,m_0)}\in\mathcal{C}]=e^{-e^{-c_0}}$, by theorem 1.12, which proves the claim.
    
\end{enumerate}
\section{}
We use the fact that a graph $G$ is planar only if $G$ is 5-degenerate. To illustrate a 5-degenerate graph on $n$ vertices, we choose a permutation $\sigma$ of the vertices, so each vertex $i\in[n]$ is assigned with the image $\sigma(i)$, and we arrange all the vertices in one row, from left to right, that is $\sigma(1),\sigma(2),\dots,\sigma(n)$. Suppose we have such an arrangement, and we want to construct a maximal 5-degenerate graph. We do this by going over every $i\in\sigma([n])$, and drawing 5 edges between $i$ and 5 of its predecessors. Easy to show that there are no other edges except the ones drawn by this procedure, because any edge from $i$ to another vertex $j$ is either included in the 5 edges from $i$ to its predecessors if $j<i$, or included in the 5 edges from $j$ to its predecessors if $i<j$. Hence, the number of edges in a 5-degenerate graph is $m\leq{5n}$ (minus a constant, because of the first 5 vertices). Fix some arrangement $\sigma_0$ and some $m_0\leq{5n}$, so the total number of possible 5-degenerated graphs with $m_0$ edges, for the arrangement $\sigma_0$, is $\binom{5n}{m_0}$, but then, the total number of graphs with $m_0$ edges is $n!\binom{5n}{m_0}$, because there are $n!$ permutations on $[n]$. Denote the property $\mathcal{P}$ that a graph $G$ is planar, so $\mathbb{P}[G\sim{G(n,m_0)}\in\mathcal{P}]\leq{\frac{n!\binom{5n}{m_0}}{\binom{N}{m_0}}}\leq{n!(\frac{5n}{N})^{m_0}}=n!\frac{5n}{\frac{n(n-1)}{2}}=n!(\frac{10}{n-1})^{m_0}$. By Stirling, we have $\mathbb{P}[G\sim{G(n,m_0)}]\approx{\sqrt{2\pi{n}}(\frac{n}{e})^n(\frac{10}{n-1})^{m_0}}=\sqrt{2\pi{n}}\cdot{n^n}{e^{-n}}{10^{m_0}}{(n-1)^{-m_0}}$. Take $m_0=(1+\epsilon)n$, for an arbitrary $\epsilon>0$, so $\mathbb{P}[G\sim{G(n,m_0)}]\approx{\sqrt{2\pi}\cdot{e^{-n}n^{\frac{1}{2}+n-n(1+\epsilon)}10^{(1+\epsilon)n}}}=\sqrt{2\pi}\cdot{e^{-n}n^{\frac{1}{2}-\epsilon{n}}10^{(1+\epsilon)n}}$, but $n^{\frac{1}{2}-\epsilon{n}}$ goes to zero faster than $10^{(1+\epsilon)n}$ goes to infinity, thus $\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,n(1+\epsilon))}\in\mathcal{P}]=0\Rightarrow\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,n(1+\epsilon))}\notin\mathcal{P}]=1$.






We prove this through the $G(n,p)$ model. Let $p=p(n)$ be a probability for which $\omega=\omega(n)=np\rightarrow\infty$ as $n\rightarrow\infty$, but $\omega(n)\leq{\log{n}}$. Denote by $T$ the number of triangles in $G$, so $\mathbb{E}T=\binom{n}{3}p^3=\frac{n(n-1)(n-2)}{3!}p^3\approx\frac{n^3}{6}p^3=\frac{(np)^3}{6}\rightarrow\infty$. Denote by $m_t$ the number of triangles $m_t=\binom{m}{3}$, then $\mathbb{E}T^2=\sum_{i,j=1}^{m_t}\mathbb{P}[T_i,T_j\in{G}]=\sum_{i=1}^{m_t}\mathbb{P}[T_i\in{G}]\sum_{j=1}^{m_t}\mathbb{P}[T_j\in{G}|T_i\in{G}]$. But the probability is equal for each of the triangles, hence $\mathbb{E}T^2=m_t\mathbb{P}[T_i\in{G}]\sum_{j=1}^{m_t}\mathbb{P}[T_j\in{G}|T_i\in{G}]=\mathbb{E}T\sum_{j=1}^{m_t}\mathbb{P}[T_j\in{G}|T_i\in{G}]$

The conditional expectation 
depends on the number of joint edges,

$3$: this is the case where the two triangles are identical, so $\sum_{j=1}^{m_t}\mathbb{P}[T_j\in{G}|T_i\in{G}]=1$.

$2$: there is no such case.

$1$: we have $3$ ways to choose two joint vertices and one new vertex, so $\sum_{j=1}^{m_t}\mathbb{P}[T_j\in{G}|T_i\in{G}]=3(n-3)p^2$

$0$: we have $\binom{n-3}{3}$ ways to choose three new vertices, and we have $3$ ways to choose one joint vertex and two other vertices, so $\sum_{j=1}^{m_t}\mathbb{P}[T_j\in{G}|T_i\in{G}]=\binom{n-3}{3}p^3+3\binom{n-1}{2}p^2$.








$\mathbb{E}X=\binom{n}{2}p^9$

$p=\frac{1}{n^{\frac{6}{3}}}\Rightarrow\mathbb{E}X=\frac{n^6}{6}\frac{1}{(n^{\frac{2}{3}-\epsilon})^9}=\frac{n^6}{n^{5+a}}$

$\mathbb{P}[X>0]\geq{\frac{(\mathbb{E}[X])^2}{\mathbb{E}[X^2]}}$

$p>\frac{1}{n^{\frac{2}{3}}}\Rightarrow{m=p\binom{n}{2}}=\frac{n(n-1)}{2n^{\frac{2}{3}}}=\frac{n^2}{2n^{\frac{2}{3}}}=\frac{n^{2-\frac{2}{3}}}{2}=\frac{n^{\frac{4}{3}}}{2}$


$m=p\binom{n}{2}=n(1+\epsilon)\Rightarrow\frac{n(n-1)}{2}p=n(1+\epsilon)\Rightarrow\frac{n-1}{2}p=1+\epsilon\rightarrow{p=\frac{2(1+\epsilon)}{n-1}}$
\end{document}
