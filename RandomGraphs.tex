\documentclass{article}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage{graphicx} % Required for inserting images

\title{RandomGraphs}
\author{haiml76 }
\date{August 2025}

\begin{document}

\maketitle

\section{}
\subsection{}
Let $G_0$ be a specific graph with $n$ vertices and $m_0$ edges, then $\mathbb{P}[G\sim{G(n,p)}=G_0]=p^{m_0}(1-p)^{\binom{n}{2}-m_0}\Rightarrow{\mathbb{P}[G\sim{G(n,p)}\in{A}]}=\mathbb{P}[\bigcup_{G_0\in{A}}G\sim{G(n,p)}=G_0]=\sum_{G_0\in{A}}p^{m_0}(1-p)^{\binom{n}{2}-m_0}$. But this is a polynomial in $p$, hence continous, and for every $0\leq{p\leq{q}}\leq{1}$. we have $\mathbb{P}[G\sim{G(n,p)}=G_0]=p^{m_0}(1-p)^{\binom{n}{2}-m_0}\leq{q^{m_0}(1-q)^{\binom{n}{2}-m_0}}=\mathbb{P}[G\sim{G(n,q)}=G_0]$, which applies also for the sum of probabilities over $\bigcup_{G_0\in{A}}G_0$. Thus, $f(p):=\mathbb{P}[G\sim{G(n,p)}\in{A}]$ is both continous and monotone increasing. We know that $\mathbb{P}[G\sim{G(n,0)}=\phi]=1\Rightarrow{\mathbb{P}[G\sim{G(n,0)}\in{A}]=0}$, and that $\mathbb{P}[G\sim{G(n,1)}\in{A}]=1$, hence $f(0)=0$ and $f(1)=1$, and by the intermediate value theorem, for each $0\leq{v}\leq{1}$, there must exist an argument $0\leq{p}\leq{1}$ s.t. $v=f(p)$. We choose $v=\frac{1}{2}$, hence there must exist some $0\leq{p^{\ast}}\leq{1}$ s.t. $v=f(p^{\ast})=\frac{1}{2}.$
\subsection{}
We check that $1-kp\leq{(1-p)^k}$, for all $k\in\mathbb{N}$, by induction.

For $k=1$ it is trivial, for $k+1$, we have $(1-p)^{k+1}=(1-p)^k(1-p)$, and by the assumption, $(1-p)^k(1-p)\geq{(1-kp)(1-p)}=1-kp-p+kp^2=1-(k+1)p+kp^2$, but $kp^2>0$, so $(1-p)^{k+1}=(1-p)^k(1-p)\geq{1-(k+1)p+kp^2}>1-(k+1)p$, which proves the assumption.

But it means that for each potential edge $e$, 

$\mathbb{P}[e\notin{G\sim{G(n,kp)}}]=1-kp\leq(1-p)^k=(\mathbb{P}[e\notin{G\sim{G(n,p)}}])^k=\mathbb{P}[e\notin{G\sim\bigcup_{i=1}^{k}G(n,p)}]\Rightarrow{\mathbb{P}[e\in{G\sim{G(n,kp)}}]\geq{\mathbb{P}[e\in{G\sim\bigcup_{i=1}^{k}G(n,p)]}}}$, 

but by a theorem coming from staged exposure, it means that if $A$ is an increasing monotone property, then $\mathbb{P}[G\sim{G(n,kp)}\in{A}]\geq{\mathbb{P}[G\sim\bigcup_{i=1}^{k}G(n,p)\in{A}]}\Rightarrow{\mathbb{P}[G\sim{G(n,kp)}\notin{A}]\leq{\mathbb{P}[G\sim\bigcup_{i=1}^{k}G(n,p)\notin{A}]}=(\mathbb{P}[G\sim{G(n,p)}\notin{A}]})^k$

\subsection{}
$\omega:=g(n)$, s.t. $\lim_{n\rightarrow\infty}g(n)=\infty$ and $\lim_{n\rightarrow\infty}\frac{g(n)}{n}=0$.

Let $n_k:=\min\{n\in\mathbb{N} : \lfloor{g(n_k)}\rfloor\geq{k}\}$, we are guaranteed to have such $n_k$ for every $k\geq{1}$, otherwise there exists some $k_0$ s.t. $\lfloor{g(n)}\rfloor\leq{k_0}$ for every $n\in\mathbb{N}$, in contradiction to $g(n)\rightarrow\infty$. 
Hence, for every $k\geq{1}$ we have $n_k\in\mathbb{N}$, s.t. $\mathbb{P}[G(n_k,g(n_k)p^{\ast})\notin{A}]\leq{\mathbb{P}[G(n_k,kp^{\ast})\notin{A}]}$, this is true because $g(n)\geq\lfloor{g(n)}\rfloor\geq{k}$ and $A$ is a monotone increasing property. But from 1.2 we know that $\mathbb{P}[G(n_k,kp^{\ast})\notin{A}]\leq{(\mathbb{P}[G(n_k,p^{\ast})\notin{A}])^k}$, but $\lim_{k\rightarrow\infty}(\mathbb{P}[G(n_k,p^{\ast})\notin{A}])^k=\lim_{k\rightarrow\infty}\frac{1}{2^k}=0\Rightarrow{\lim_{n\rightarrow\infty}\mathbb{P}[G(n,g(n){p^{\ast}})\in{A}]}=\lim\mathbb{P}[G(n,\omega{p^{\ast}})\in{A}]=1$.

For $\mathbb{P}[G(n,\frac{p^{\ast}}{g(n)})\in{A}]$, we observe that $0\leq{p^{\ast}}\leq{1}\Rightarrow{\lim_{n\rightarrow\infty}\frac{p^{\ast}}{g(n)}}\leq{\lim_{n\rightarrow\infty}\frac{1}{g(n)}}=0$, as $g(n)$ tends to infinity.
But then $\lim_{n\rightarrow\infty}\mathbb{P}[G(n,\frac{p^{\ast}}{g(n)})\in{A}]=\lim_{p\rightarrow{0}}\mathbb{P}[G(n,p)\in{A}]=\mathbb{P}[G(n,0)\in{A}]$, as $\mathbb{P}[G(n,p)\in{A}]$ is continuous, but from 1.1 we know that $\mathbb{P}[G(n,0)\in{A}]=0$.

\section{}
Intuitively, we observe that for any finite graph on $n\geq{3}$ vertices a triangle can appear starting from $m=3$ which is a constant, but the graph cannot be connected before at least $n-1$ edges appear, which depends on $n$, so when $n\rightarrow\infty$, the distance $(n-1)-3$ also tends to infinity. But we need to prove this formally.

We use two theorems which are common in the literature, and were studied in class.
\begin{enumerate}
    \item Let $m=\frac{1}{2}n(\log{n}+c_n)$. Then

    $\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,m)}\in\mathcal{C}]=\begin{cases}
        0, & c_n\rightarrow{-\infty} \\
        e^{-e^{-c}}, & c_n\rightarrow{c} \\
        1, & c_n\rightarrow\infty \\
    \end{cases}$

    where $\mathcal{C}$ is the property of being connected, and $c$ is some constant.

    \textbf{Proof essence:}

    We go through the $G(n,p)$ model.
Let $C_k$ be the number of connected components with $k$ vertices. Clearly we count only up to $k=\frac{n}{2}$. Then the probability of $G\sim{G(n,p)}$ having more than one connected component is the probability of the union of the events $\{C_k>0\}_{k=1}^\frac{n}{2}$, that is $\mathbb{P}[\bigcup_{k=1}^\frac{n}{2}C_k>0]$. Denote by $\mathcal{C}$ the property of being connected, we notice that $\mathbb{P}[G\sim{G(n,p)}\notin\mathcal{C}]\leq\mathbb{P}[\bigcup_{k=1}^\frac{n}{2}C_k>0]\leq\sum_{k=1}^\frac{n}{2}\mathbb{P}[C_k>0]$, because if there is at least one connected component of up to $k=\frac{n}{2}$ vertices in $G$, then $G$ is not connected, so not being connected is a partial event to the union of having connected components. We separate the sum $\sum_{k=1}^\frac{n}{2}\mathbb{P}[C_k>0]=\mathbb{P}[C_1>0]+\sum_{k=2}^\frac{n}{2}\mathbb{P}[C_k>0]$, because we can bound each of two cases $k=1$ and $2\leq{k}\leq\frac{n}{2}$ separately. By Markov inequality, $\sum_{k=2}^\frac{n}{2}\mathbb{P}[C_k\geq{1}]\leq\sum_{k=2}^\frac{n}{2}\mathbb{E}C_k$. For each component of size $k$ we have $\binom{n}{k}$ choices of $k$ out of $n$ vertices. We need to have at least $k-1$ edges connecting the $k$ vertices in the component, that is $p^{k-1}$, and we must not have edges between each of the vertices in the component and the other $n-k$ vertices in the graph, that is $(1-p)^{k(n-k)}$. Considering all the possible arrangements of $k$ components for all the possible counts of $C_k$, we have $\sum_{k=2}^\frac{n}{2}\mathbb{E}C_k\leq\sum_{k=2}^\frac{n}{2}\binom{n}{k}k^{k-2}p^{k-1}(1-p)^{k(n-k)}$. We can bound this sum by $o(1)$, so the probability $\sum_{k=2}^\frac{n}{2}\mathbb{P}[C_k>0]$ asymptotically contributes nothing to $G$ not being connected. now we observe the probability of having no isolated vertices $\mathbb{P}[C_1=0]$ behaves according to the claim that if we take $p=\frac{log{n}+c}{n}$, then $\lim_{n\rightarrow\infty}\mathbb{P}[C_1=0]=e^{-e^{-c}}\Rightarrow\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,p)}\in\mathcal{C}]\approx\lim_{n\rightarrow\infty}\mathbb{P}[C_1=0]+o(1)\approx{e^{-e^{-c}}}<1$, for any constant $c$.

    \item Let $m$ be s.t. $\lim_{n\rightarrow\infty}\frac{m}{n}=\infty$ then $\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,m)}\in\mathcal{T}]=1$, where $\mathcal{T}$ is the property of having at least one triangle.

    \textbf{Proof essence:}

    We prove this through the $G(n,p)$ model. Let $p=p(n)$ be a probability for which $\omega=\omega(n)=np\rightarrow\infty$ as $n\rightarrow\infty$, but $\omega(n)=np\leq{\log{n}}\Rightarrow{p\leq\frac{\log{n}}{n}}$. Denote by $T$ the number of triangles in $G$, so $\mathbb{E}T=\binom{n}{3}p^3=\frac{n(n-1)(n-2)}{3!}p^3\approx\frac{n^3}{6}p^3=\frac{(np)^3}{6}\rightarrow\infty$. Denote by $m_t$ the number of triangles $m_t=\binom{m}{3}$, then $\mathbb{E}T^2=\sum_{i,j=1}^{m_t}\mathbb{P}[T_i,T_j\in{G}]=\sum_{i=1}^{m_t}\mathbb{P}[T_i\in{G}]\sum_{j=1}^{m_t}\mathbb{P}[T_j\in{G}|T_i\in{G}]$. But the probability is equal for each of the triangles, hence $\mathbb{E}T^2=m_t\mathbb{P}[T_i\in{G}]\sum_{j=1}^{m_t}\mathbb{P}[T_j\in{G}|T_i\in{G}]=\mathbb{E}T\sum_{j=1}^{m_t}\mathbb{P}[T_j\in{G}|T_i\in{G}]$

We calculate $\sum_{j=1}^{m_t}\mathbb{P}[T_j\in{G}|T_i\in{G}]$ by counting the expected number of triangles in $G$, when there is already a triangle in $G$. For that, we need to break the expected count into different cases, by the number of joint edges between the existing triangle and the new triangles. Denote by $\mathbb{E}_k$ the count of new triangles when the number of joint edges is $k$, then $\sum_{j=1}^{m_t}\mathbb{P}[T_j\in{G}|T_i\in{G}]=\sum_{k=0}^3\mathbb{E}_k$.
We check the different cases,

$k=3$: Only the existing triangle is a.s. (or surely) sharing $3$ edges with itself, thus $\mathbb{E}_3=1$.

$k=2$: There is a.s. (surely) no triangle sharing only two edges with another, otherwise it is sharing also the third edge and this is the case $\mathbb{E}_3$, thus $\mathbb{E}_2=0$.

$k=1$: There are $3$ choices of the $2$ shared vertices, for each we choose a new vertex not in the triangle, and draw $2$ edges from this vertex to the $2$ existing vertices, thus $\mathbb{E}_{1}=3(n-3)p^2$.

$k=0$: There are two cases here, whether there is a joint vertex a not, but either way, the approximated number of choices for the new vertices is $\binom{n-3}{3}\leq\binom{n}{3}$, and we have $3$ new edges, so the probability is $p^3$, thus $\mathbb{E}_0\leq\binom{n}{3}p^3=\mathbb{E}T$. Then we observe that $Var{T}=\mathbb{E}T^2-(\mathbb{E}T)^2\leq\mathbb{E}T(1+3(n-3)p^2+\mathbb{E}T)-(\mathbb{E}T)^2=(1+3(n-3)p^2)\mathbb{E}T$. But we chose $p\leq{\frac{\log{n}}{n}}\Rightarrow{(1+\binom{n}{3}p^2})\mathbb{E}T\leq{2\mathbb{E}T}$. Hence, we can use the Chebyshev inequality on the following claim,

The probability that $G$ has no triangles $\{T=0\}$ is a partial event of the event $\{T : |T-\mathbb{E}T|\geq\mathbb{E}T\}$, because $T=0\Rightarrow|0-\mathbb{E}T|=\mathbb{E}T$. Hence, $\mathbb{P}[T=0]\leq\mathbb{P}[|T-\mathbb{E}T|\geq\mathbb{E}T]\leq\frac{VarT}{(\mathbb{E}T)^2}$, by the Chebyshev inequality. But $VarT\leq{2\mathbb{E}T}\Rightarrow\mathbb{P}[T=0]\leq\frac{VarT}{(\mathbb{E}T)^2}\leq\frac{2\mathbb{E}T}{(\mathbb{E}T)^2}=\frac{2}{\mathbb{E}T}$, but $\mathbb{E}T\rightarrow\infty$ when $n\rightarrow\infty$, thus $\mathbb{P}[T=0]=0$, when $n\rightarrow\infty$, so $\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,p)}\notin\mathcal{T}]=0\Rightarrow\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,p)}\in\mathcal{T}]=1$, for $p\leq\frac{\log{n}}{n}$, and since $\mathcal{T}$ is a monotone increasing property, this will be true for any greater $p$. But $m\approx\binom{n}{2}p=\frac{n(n-1)}{2}p\approx\frac{n(n-1)\log{n}}{2n}\approx{n\log{n}}\Rightarrow\frac{n\log{n}}{n}=\log{n}\rightarrow\infty$, when $n\rightarrow\infty$, which shows that it is enough to have $m=O(\log{n})$ edges in $G\sim{G(n,m)}$ so that $G\sim{G(n,m)}\in\mathcal{T}$.
\end{enumerate}
    
    Using the two theorems above. Let $c_0$ be some constant, and $m_0:=\frac{1}{2}n(\log{n}+c_0)$, then $\lim_{n\rightarrow\infty}\frac{m_0}{n}=\lim_{n\rightarrow\infty}\frac{n(\log{n}+c_0)}{2n}=\lim_{n\rightarrow\infty}\frac{\log{n}+c_0}{2}=\infty\Rightarrow{\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,m_0)}\in\mathcal{T}]}=1$, by theorem 4.1, but $\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,m_0)}\in\mathcal{C}]=e^{-e^{-c_0}}$, by theorem 1.12, which proves the claim.
\section{}
We use the fact that a graph $G$ is planar only if $G$ is 5-degenerate. To illustrate a 5-degenerate graph on $n$ vertices, we choose a permutation $\sigma$ of the vertices, so each vertex $i\in[n]$ is assigned with the image $\sigma(i)$, and we arrange all the vertices in one row, from left to right, that is $\sigma(1),\sigma(2),\dots,\sigma(n)$. Suppose we have such an arrangement, and we want to construct a maximal 5-degenerate graph. We do this by going over every $i\in\sigma([n])$, and drawing 5 edges between $i$ and 5 of its predecessors. Easy to show that there are no other edges except the ones drawn by this procedure, because any edge from $i$ to another vertex $j$ is either included in the 5 edges from $i$ to its predecessors if $j<i$, or included in the 5 edges from $j$ to its predecessors if $i<j$. Hence, the number of edges in a 5-degenerate graph is $m\leq{5n}$ (minus a constant, because of the first 5 vertices). Fix some arrangement $\sigma_0$ and some $m_0\leq{5n}$, so the total number of possible 5-degenerated graphs with $m_0$ edges, for the arrangement $\sigma_0$, is $\binom{5n}{m_0}$, but then, the total number of graphs with $m_0$ edges is $n!\binom{5n}{m_0}$, because there are $n!$ permutations on $[n]$. Denote the property $\mathcal{P}$ that a graph $G$ is planar, so $\mathbb{P}[G\sim{G(n,m_0)}\in\mathcal{P}]\leq{\frac{n!\binom{5n}{m_0}}{\binom{N}{m_0}}}\leq{n!(\frac{5n}{N})^{m_0}}=n!\frac{5n}{\frac{n(n-1)}{2}}=n!(\frac{10}{n-1})^{m_0}$. By Stirling, we have $\mathbb{P}[G\sim{G(n,m_0)}]\approx{\sqrt{2\pi{n}}(\frac{n}{e})^n(\frac{10}{n-1})^{m_0}}=\sqrt{2\pi{n}}\cdot{n^n}{e^{-n}}{10^{m_0}}{(n-1)^{-m_0}}$. Take $m_0=(1+\epsilon)n$, for an arbitrary $\epsilon>0$, so $\mathbb{P}[G\sim{G(n,m_0)}]\approx{\sqrt{2\pi}\cdot{e^{-n}n^{\frac{1}{2}+n-n(1+\epsilon)}10^{(1+\epsilon)n}}}=\sqrt{2\pi}\cdot{e^{-n}n^{\frac{1}{2}-\epsilon{n}}10^{(1+\epsilon)n}}$, but $n^{\frac{1}{2}-\epsilon{n}}$ goes to zero faster than $10^{(1+\epsilon)n}$ goes to infinity, thus $\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,n(1+\epsilon))}\in\mathcal{P}]=0\Rightarrow\lim_{n\rightarrow\infty}\mathbb{P}[G\sim{G(n,n(1+\epsilon))}\notin\mathcal{P}]=1$.

\end{document}
