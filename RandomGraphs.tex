\documentclass{article}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage{graphicx} % Required for inserting images

\title{RandomGraphs}
\author{haiml76 }
\date{August 2025}

\begin{document}

\maketitle

\section{}
\subsection{}
Let $G_0$ be a specific graph with $n$ vertices and $m_0$ edges, then $\mathbb{P}[G\sim{G(n,p)}=G_0]=p^{m_0}(1-p)^{\binom{n}{2}-m_0}\Rightarrow{\mathbb{P}[G\sim{G(n,p)}\in{A}]}=\mathbb{P}[\bigcup_{G_0\in{A}}G\sim{G(n,p)}=G_0]=\sum_{G_0\in{A}}p^{m_0}(1-p)^{\binom{n}{2}-m_0}$. But this is a polynomial in $p$, hence continous, and for every $0\leq{p\leq{q}}\leq{1}$. we have $\mathbb{P}[G\sim{G(n,p)}=G_0]=p^{m_0}(1-p)^{\binom{n}{2}-m_0}\leq{q^{m_0}(1-q)^{\binom{n}{2}-m_0}}=\mathbb{P}[G\sim{G(n,q)}=G_0]$, which applies also for the sum of probabilities over $\bigcup_{G_0\in{A}}G_0$. Thus, $f(p):=\mathbb{P}[G\sim{G(n,p)}\in{A}]$ is both continous and monotone increasing. We know that $\mathbb{P}[G\sim{G(n,0)}=\phi]=1\Rightarrow{\mathbb{P}[G\sim{G(n,0)}\in{A}]=0}$, and that $\mathbb{P}[G\sim{G(n,1)}\in{A}]=1$, hence $f(0)=0$ and $f(1)=1$, and by the intermediate value theorem, for each $0\leq{v}\leq{1}$, there must exist an argument $0\leq{p}\leq{1}$ s.t. $v=f(p)$. We choose $v=\frac{1}{2}$, hence there must exist some $0\leq{p^{\ast}}\leq{1}$ s.t. $v=f(p^{\ast})=\frac{1}{2}.$
\subsection{}
We check that $1-kp\leq{(1-p)^k}$, for all $k\in\mathbb{N}$, by induction.

For $k=1$ it is trivial, for $k+1$, we have $(1-p)^{k+1}=(1-p)^k(1-p)$, and by the assumption, $(1-p)^k(1-p)\geq{(1-kp)(1-p)}=1-kp-p+kp^2=1-(k+1)p+kp^2$, but $kp^2>0$, so $(1-p)^{k+1}=(1-p)^k(1-p)\geq{1-(k+1)p+kp^2}>1-(k+1)p$, which proves the assumption.

But it means that for each potential edge $e$, 

$\mathbb{P}[e\notin{G\sim{G(n,kp)}}]=1-kp\leq(1-p)^k=(\mathbb{P}[e\notin{G\sim{G(n,p)}}])^k=\mathbb{P}[e\notin{G\sim\bigcup_{i=1}^{k}G(n,p)}]\Rightarrow{\mathbb{P}[e\in{G\sim{G(n,kp)}}]\geq{\mathbb{P}[e\in{G\sim\bigcup_{i=1}^{k}G(n,p)]}}}$, 

but by a theorem coming from staged exposure, it means that if $A$ is an increasing monotone property, then $\mathbb{P}[G\sim{G(n,kp)}\in{A}]\geq{\mathbb{P}[G\sim\bigcup_{i=1}^{k}G(n,p)\in{A}]}\Rightarrow{\mathbb{P}[G\sim{G(n,kp)}\notin{A}]\leq{\mathbb{P}[G\sim\bigcup_{i=1}^{k}G(n,p)\notin{A}]}=(\mathbb{P}[G\sim{G(n,p)}\notin{A}]})^k$

\subsection{}
$\omega:=g(n)$, s.t. $\lim_{n\rightarrow\infty}g(n)=\infty$ and $\lim_{n\rightarrow\infty}\frac{g(n)}{n}=0$.

Let $n_k:=\min\{n\in\mathbb{N} : \lfloor{g(n_k)}\rfloor\geq{k}\}$, we are guaranteed to have such $n_k$ for every $k\geq{1}$, otherwise there exists some $k_0$ s.t. $\lfloor{g(n)}\rfloor\leq{k_0}$ for every $n\in\mathbb{N}$, in contradiction to $g(n)\rightarrow\infty$. 
Hence, for every $k\geq{1}$ we have $n_k\in\mathbb{N}$, s.t. $\mathbb{P}[G(n_k,g(n_k)p^{\ast})\notin{A}]\leq{\mathbb{P}[G(n_k,kp^{\ast})\notin{A}]}$, this is true because $g(n)\geq\lfloor{g(n)}\rfloor\geq{k}$ and $A$ is a monotone increasing property. But from 1.2 we know that $\mathbb{P}[G(n_k,kp^{\ast})\notin{A}]\leq{(\mathbb{P}[G(n_k,p^{\ast})\notin{A}])^k}$, but $\lim_{k\rightarrow\infty}(\mathbb{P}[G(n_k,p^{\ast})\notin{A}])^k=\lim_{k\rightarrow\infty}\frac{1}{2^k}=0\Rightarrow{\lim_{n\rightarrow\infty}\mathbb{P}[G(n,g(n){p^{\ast}})\in{A}]}=\lim\mathbb{P}[G(n,\omega{p^{\ast}})\in{A}]=1$.

For $\mathbb{P}[G(n,\frac{p^{\ast}}{g(n)})\in{A}]$, we observe that $0\leq{p^{\ast}}\leq{1}\Rightarrow{\lim_{n\rightarrow\infty}\frac{p^{\ast}}{g(n)}}\leq{\lim_{n\rightarrow\infty}\frac{1}{g(n)}}=0$, as $g(n)$ tends to infinity.
But then $\lim_{n\rightarrow\infty}\mathbb{P}[G(n,\frac{p^{\ast}}{g(n)})\in{A}]=\lim_{p\rightarrow{0}}\mathbb{P}[G(n,p)\in{A}]=\mathbb{P}[G(n,0)\in{A}]$, as $\mathbb{P}[G(n,p)\in{A}]$ is continuous, but from 1.1 we know that $\mathbb{P}[G(n,0)\in{A}]=0$.

\section{}
Intuitively, we observe that for any graph on $n\geq{3}$ vertices a triangle can appear starting from $m=3$ which is a constant, but the graph cannot be connected before at least $n-1$ edges appear, which depends on $n$, so when $n\rightarrow\infty$, the distance $(n-1)-3$ also tends to infinity. But we need to prove this formally.
We shall partially repeat some well-known facts. Let $G\sim{G(n,p)}$, the probability of having at least one triangle in $G$ has a threshold. Let $T$ be the number of triangles in $G$, then $\mathbb{E}[T]=\binom{n}{3}p^3\Rightarrow{\lim_{n\rightarrow\infty}}\mathbb{E}[T]=\lim_{n\rightarrow\infty}\binom{n}{3}p^3=\lim_{n\rightarrow\infty}\frac{n(n-1)(n-2)}{3!}p^3$. For every $0\leq{p(n)}\leq{1}$, we have 

$\lim_{n\rightarrow\infty}\frac{n(n-1)(n-2)}{6}p(n)^3=     \begin{cases}
       0, & p(n)<<\frac{1}{n}\\
       1, & p(n)>>\frac{1}{n}\\
     \end{cases}$

But by Markov's inequality, $\mathbb{P}[T\geq{1}]\leq\frac{\mathbb{E}[T]}{1}$, so in the case of $p(n)<<\frac{1}{n}$ we have that $\lim_{n\rightarrow\infty}\mathbb{P}[T\geq{1}]\leq{lim_{n\rightarrow\infty}\mathbb{E}[T]=0}$.
For $p>>\frac{1}{n}$, we use the second moment method, we have the inequality $\mathbb{P}[T\geq{1}]\geq{\frac{\mathbb{E}[T]^2}{\mathbb{E}[T^2]}}=\frac{[\binom{n}{3}p^3]^2}{\mathbb{E}[T^2]}$. But $T^2=\sum\mathbbm{1}_{\{i,j,k\}\in\mathcal{T}}\sum\mathbbm{1}_{\{f,g,h\}\in\mathcal{T}}$, where $\{i,j,k\}$ and $\{f,g,h\}$ are triplets of vertices and $\mathcal{T}$ is the set of all potential triangles in $G$. There are different ways to choose one triplet and then choose a second triplet, the one that yields the largest count of vertices is when $\{i,j,k\}\cap\{f,g,h\}=\phi$, we denote $T_0$ the potential number of triplets in the case of the intersection being $\phi$, which means no joint vertex, $T_1$ the case of one joint vertex, $T_2$ the case of two joint vertices, and $T_3$ the case of choosing the same triangle twice.

Thus $T_0=\binom{n}{3}\binom{n-3}{3}$. 

For $T_1$ we have $\binom{n}{3}$ choices of the first triplet, and $3$ options for choosing one of the vertices of the first triplet, and then $\binom{n-3}{2}$ choices for the other two vertices of the second triplet, so $T_1=3\binom{n}{3}\binom{n-3}{2}$, and $T_2=3\binom{n}{3}(n-3)$, and $T_3=\binom{n}{3}$. 

We observe that in the case of $T_0$ and the case of $T_1$ we have $6$ distinct edges for every two triangles, so their probability is $p^6$, but in the case of $T_2$ we have one joint edges, so only 5 distinct edges for every two triangles, and in the case of choosing the same triplet twice, we have the same three edges chosen twice, but the probability for that remains $p^3$. Thus the corresponding expectations of $T_1$, $T_2$ and $T_3$ are $O(n^5p^6)$, $O(n^4p^5)$ and $O(n^3p^3)$, respectively. Thus $\frac{\mathbb{E}[T]^2}{\mathbb{E}[T^2]}=\frac{\binom{n}{3}^2p^6}{\binom{n}{3}\binom{n-3}{3}p^6+o(n^6p^6)}=1-o(1)$, but $\mathbb{P}[T\geq{1}]\geq\frac{\mathbb{E}[T]^2}{\mathbb{E}[T^2]}=1-o(1)$. Notice that this is true only if $p>>\frac{1}{p}$, for which $\mathbb{E}[T]$ tends to infinity.

For connectedness, the threshold is $\frac{\log{n}}{n}$.
We know that for a random graph process, each step $0\leq{m}\leq\binom{n}{2}$ has the same distribution of $G(n,m)$, so we translate our thresholds from $G(n,p)$ to $G(n,m)$ by taking $m=\binom{n}{2}p+O(\sqrt{\binom{n}{2}p(1-p)})$. Thus, the $G(n,m)$ threshold for triangles becomes $m_t:=\binom{n}{2}\frac{1}{n}+O(\sqrt{\binom{n}{2}\frac{1}{n}(1-\frac{1}{n})})\approx\binom{n}{2}\frac{1}{n}$, and the threshold for connectedness becomes $m_c:=\binom{n}{2}\frac{\log{n}}{n}+O(\sqrt{\binom{n}{2}\frac{\log{n}}{n}(1-\frac{\log{n}}{n})})\approx\binom{n}{2}\frac{\log{n}}{n}$. We take the sequence $M_n:=\{\frac{m_c}{m_t}\}\approx\log{n}$, but $\lim_{n\rightarrow\infty}\log{n}=\infty$, hence $\lim_{n\rightarrow\infty}\mathbb{P}[m_c\geq{m_t}]=\lim_{n\rightarrow\infty}\mathbb{P}[\frac{m_c}{m_t}\geq{1}]=\infty$.
\end{document}
